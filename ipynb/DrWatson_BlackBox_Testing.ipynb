{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#cloning the malware dataset into the google colab environment.\n",
        "\n",
        "!git clone https://github.com/iosifache/DikeDataset.git"
      ],
      "metadata": {
        "id": "Xb5tvNmcvbpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code section contains all the pip install commands.\n",
        "\n",
        "!pip install pefile\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "MjiU3FA0w2aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This section contains all the import(s).\n",
        "\n",
        "import pefile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "URHTviDH-reR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains all the constants used.\n",
        "\n",
        "N = 200\n",
        "Trainsize = 80\n",
        "Testsize = 20\n",
        "Decimal = 7\n",
        "Maxvalue = 255\n",
        "Layer1 = 8\n",
        "Layer2 = 4\n",
        "Layer3 = 1\n",
        "\n",
        "benign_directory = '/content/DikeDataset/files/benign'\n",
        "malware_directory = '/content/DikeDataset/files/malware'\n",
        "labels_directory = '/content/DikeDataset/labels/malware.csv'"
      ],
      "metadata": {
        "id": "uIHBo2V2LS4u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This section extracts the data for a particular section name.\n",
        "\n",
        "def extract_section_data(pe, section_name):\n",
        "  for section in pe.sections:\n",
        "    if section.Name.decode('utf-8').strip('\\x00') == section_name:\n",
        "      # Found the section with section name, converting the section data into hex and returning.\n",
        "      return bytes.fromhex(section.get_data().hex())\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "vqiOsW95yoCh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract data from \"text\" section of the executable, convert it into an integer list, normalize and return\n",
        "\n",
        "def get_normalized_data(file_path, section_name):\n",
        "  try:\n",
        "    pe = pefile.PE(file_path)\n",
        "    section_data = extract_section_data(pe, section_name)\n",
        "    integer_list = [int(byte) for byte in section_data]\n",
        "    normalized_data = [round(value / Maxvalue, Decimal) for value in integer_list]\n",
        "    return normalized_data\n",
        "  except:\n",
        "    print(\"Something unexpected happened\")"
      ],
      "metadata": {
        "id": "Mp7GUVFPyySp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are different types of malware files, consider only the trojan files for now.\n",
        "\n",
        "categorized_data = pd.read_csv(labels_directory)\n",
        "\n",
        "# sort the data as per the probability of it being a malware from the trojan family\n",
        "categorized_data_sorted = categorized_data.sort_values(by = 'trojan', ascending = False)\n",
        "\n",
        "trojan_files = categorized_data_sorted['hash'][:N]\n",
        "\n",
        "# The 'files' variable contains N number of file names (without extension) from the trojan family\n",
        "files = np.array(trojan_files)"
      ],
      "metadata": {
        "id": "cS60bXVPAOke"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the text section data from the files which are contained in the 'files' variable\n",
        "trojan_text_section = [] # this will be used as a list of lists where each list will contain the data about a particular trojan file\n",
        "file_extension = '.exe'\n",
        "section_name = '.text'\n",
        "for name in files:\n",
        "  relative_file_path = os.path.join(malware_directory, name + file_extension)\n",
        "  byte_stream_data = get_normalized_data(relative_file_path, section_name)\n",
        "  if byte_stream_data:\n",
        "    # For the given file name found the byte stream data.\n",
        "    trojan_text_section.append(byte_stream_data)\n",
        "  else:\n",
        "    print(\"No Data Found for the given file: \", name + file_extension)\n"
      ],
      "metadata": {
        "id": "8ml3_IQUBd5q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Till now found the trojan family malware data, now need a set of bening executables data.\n",
        "benign_file_text_section = []\n",
        "benign_dataset = os.listdir(benign_directory)\n",
        "sample_benign_dataset = random.sample(benign_dataset, N)\n",
        "for name in sample_benign_dataset:\n",
        "  relative_file_path = os.path.join(benign_directory, name)\n",
        "  byte_stream_data = get_normalized_data(relative_file_path, section_name)\n",
        "  if byte_stream_data:\n",
        "    benign_file_text_section.append(byte_stream_data)\n",
        "  else:\n",
        "    print(\"No Data Found for the given benign file: \", name)\n",
        "\n",
        "print(len(benign_file_text_section))\n",
        "print(len(trojan_text_section))"
      ],
      "metadata": {
        "id": "Gk5mO-GjEZqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network training\n",
        "# dataset - benign_file_text_section, trojan_text_section\n",
        "# forming x_train and y_train\n",
        "\n",
        "benign_features = max(len(list) for list in benign_file_text_section)\n",
        "malware_features = max(len(list) for list in trojan_text_section)\n",
        "\n",
        "number_of_features = max(benign_features, malware_features)\n",
        "\n",
        "for i in range(0, len(benign_file_text_section)):\n",
        "  arr = np.array(benign_file_text_section[i])\n",
        "  benign_file_text_section[i] = np.pad(arr, (0, number_of_features-len(arr)), mode='constant')\n",
        "\n",
        "for i in range(len(trojan_text_section)):\n",
        "  arr = np.array(trojan_text_section[i])\n",
        "  trojan_text_section[i] = np.pad(arr, (0, number_of_features-len(arr)), mode='constant')\n",
        "\n",
        "benign_file_text_section = np.array(benign_file_text_section)\n",
        "trojan_text_section = np.array(trojan_text_section)\n",
        "\n",
        "x_train = np.vstack((benign_file_text_section[:Trainsize, :], trojan_text_section[:Trainsize, :]))\n",
        "y_train = np.hstack((np.zeros(Trainsize), np.ones(Trainsize)))\n",
        "\n",
        "x_test = np.vstack((benign_file_text_section[-Testsize:, :], trojan_text_section[-Testsize:, :]))\n",
        "y_test = np.hstack((np.zeros(Testsize), np.ones(Testsize)))"
      ],
      "metadata": {
        "id": "b2q7ZilfTHpH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the neural net\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(Layer1, activation='relu', input_shape=(number_of_features,)),  # Adjust input shape based on your features\n",
        "    layers.Dense(Layer2, activation='relu'),\n",
        "    layers.Dense(Layer3, activation='sigmoid')  # Binary classification, use 'softmax' for multi-class\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs = 50, batch_size = 16, validation_split= 0.2)"
      ],
      "metadata": {
        "id": "1nhmxCANeuDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model by doing predictions\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, binary_predictions)\n",
        "precision = precision_score(y_test, binary_predictions)\n",
        "recall = recall_score(y_test, binary_predictions)\n",
        "f1 = f1_score(y_test, binary_predictions)\n",
        "conf_matrix = confusion_matrix(y_test, binary_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11NsL07z7nug",
        "outputId": "e7a134d9-1ad0-4f03-8490-cdb8b919549e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.8\n",
            "Precision: 0.9285714285714286\n",
            "Recall: 0.65\n",
            "F1-Score: 0.7647058823529412\n",
            "Confusion Matrix:\n",
            "[[19  1]\n",
            " [ 7 13]]\n"
          ]
        }
      ]
    }
  ]
}